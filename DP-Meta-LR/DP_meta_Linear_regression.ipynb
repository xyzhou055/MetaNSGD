{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFhto1JmM4HE"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4YTMAai5NUXa",
        "outputId": "6df40c0e-aa9a-477e-8681-b532f1026c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-privacy\n",
            "  Downloading tensorflow_privacy-0.8.0-py3-none-any.whl (287 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 39.4 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30 kB 46.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51 kB 38.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61 kB 43.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 92 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 102 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 112 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 122 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 133 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 163 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 174 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 184 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 194 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 204 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 215 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 225 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 235 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 245 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 256 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 266 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 276 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 287 kB 32.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.1.7)\n",
            "Collecting pandas~=1.1.4\n",
            "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 90.3 MB/s \n",
            "\u001b[?25hCollecting scipy~=1.5.0\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.21.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.21.6)\n",
            "Collecting matplotlib~=3.3.4\n",
            "  Downloading matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 89.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn~=1.0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.0.2)\n",
            "Collecting attrs~=21.2.0\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow-datasets~=4.5.2\n",
            "  Downloading tensorflow_datasets-4.5.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 75.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-probability~=0.15.0\n",
            "  Downloading tensorflow_probability-0.15.0-py2.py3-none-any.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 25.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.8.0)\n",
            "Requirement already satisfied: absl-py~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py~=1.0.0->tensorflow-privacy) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib~=3.3.4->tensorflow-privacy) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.4->tensorflow-privacy) (2022.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=1.0.2->tensorflow-privacy) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=1.0.2->tensorflow-privacy) (1.1.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 85.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.14.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.44.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (14.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.25.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.4->tensorflow-privacy) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.4->tensorflow-privacy) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (4.64.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (5.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (0.3.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (1.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability~=0.15.0->tensorflow-privacy) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability~=0.15.0->tensorflow-privacy) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets~=4.5.2->tensorflow-privacy) (1.56.0)\n",
            "Installing collected packages: tf-estimator-nightly, scipy, tensorflow-probability, tensorflow-datasets, pandas, matplotlib, attrs, tensorflow-privacy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.16.0\n",
            "    Uninstalling tensorflow-probability-0.16.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.16.0\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.0.1\n",
            "    Uninstalling tensorflow-datasets-4.0.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.4.0\n",
            "    Uninstalling attrs-21.4.0:\n",
            "      Successfully uninstalled attrs-21.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed attrs-21.2.0 matplotlib-3.3.4 pandas-1.1.5 scipy-1.5.4 tensorflow-datasets-4.5.2 tensorflow-privacy-0.8.0 tensorflow-probability-0.15.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow-privacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "from util import task_sampling, average_vars, meta_update, gradient_clipping, Add_noise, average_vars_batch\n",
        "import copy\n",
        "from numpy.linalg import norm\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorflow_privacy.privacy.analysis.compute_noise_from_budget_lib import compute_noise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPLEUjQYGKge"
      },
      "outputs": [],
      "source": [
        "N_train_task = 1000\n",
        "N_sample_per_task = 10\n",
        "N_test_task = 400\n",
        "\n",
        "train_path = './data/train/'\n",
        "test_path = './data/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjnS5PEcY85T"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!mkdir data/test\n",
        "!mkdir data/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V0XTUPJr3Nv"
      },
      "source": [
        "Data Generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYC5KHz7GQWp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def data_generation():\n",
        "    d = 30    #dimension\n",
        "\n",
        "    w_bar_1 = np.concatenate(([2]*10, [0]*10, [0]*10))\n",
        "    w_bar_2 = np.concatenate(([0]*10, [-4]*10, [0]*10))\n",
        "    w_bar_3 = np.concatenate(([0]*10, [0]*10, [6]*10))\n",
        "\n",
        "\n",
        "    N_train_task = 1000\n",
        "    N_sample_per_task = 10\n",
        "    N_test_task = 500\n",
        "    sigma = 0.5\n",
        "    noise_sigma = 0.5\n",
        "    train_path = './data/train/'\n",
        "    test_path = './data/test/'\n",
        "\n",
        "    for i in range(N_train_task):\n",
        "\n",
        "        choice = np.random.rand()\n",
        "        if choice < 0.33:\n",
        "            w_bar = w_bar_1\n",
        "        elif choice <0.67:\n",
        "            w_bar = w_bar_2\n",
        "        else:\n",
        "            w_bar = w_bar_3\n",
        "\n",
        "        w = np.random.normal(w_bar, sigma).reshape(d, 1)\n",
        "        X = np.random.random((N_sample_per_task, d))\n",
        "        l2norm = norm(X, axis=1, ord=2)\n",
        "        X = X/l2norm[:, None]\n",
        "        noise = np.random.normal(0, noise_sigma, N_sample_per_task).reshape(N_sample_per_task, 1)\n",
        "        y = np.matmul(X, w) + noise\n",
        "\n",
        "        tensor_X = torch.Tensor(X)\n",
        "        tensor_y = torch.Tensor(y)\n",
        "\n",
        "        dataset = TensorDataset(tensor_X, tensor_y)\n",
        "        torch.save(dataset, train_path+str(i+1)+'.pt')\n",
        "\n",
        "    for i in range(N_test_task):\n",
        "\n",
        "        choice = np.random.rand()\n",
        "        if choice < 0.33:\n",
        "            w_bar = w_bar_1\n",
        "        elif choice < 0.67:\n",
        "            w_bar = w_bar_2\n",
        "        else:\n",
        "            w_bar = w_bar_3\n",
        "        w = np.random.normal(w_bar, sigma).reshape(d, 1)\n",
        "        X = np.random.random((N_sample_per_task*5, d))\n",
        "        l2norm = norm(X, axis=1, ord=2)\n",
        "        X = X / l2norm[:, None]\n",
        "        noise = np.random.normal(0, noise_sigma, N_sample_per_task*5).reshape(N_sample_per_task*5, 1)\n",
        "        y = np.matmul(X, w) + noise\n",
        "\n",
        "        tensor_X = torch.Tensor(X)\n",
        "        tensor_y = torch.Tensor(y)\n",
        "\n",
        "        dataset = TensorDataset(tensor_X, tensor_y)\n",
        "        torch.save(dataset, test_path + str(i + 1) + '.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC1No0aYGUjZ"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzdxFxr9GUSU"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(30, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "def model_train(model, dataloader, old_parameters, ntier, optim, loss_fn, lam_reg):\n",
        "\n",
        "    for _ in range(ntier):\n",
        "        inputs, labels = next(iter(dataloader))\n",
        "        optim.zero_grad()\n",
        "        predict = model(inputs)\n",
        "        loss = loss_fn(predict, labels)\n",
        "        loss_fn_2 = nn.MSELoss(reduction='sum')\n",
        "\n",
        "        loss_w = [loss_fn_2(w, w_meta) for w, w_meta in zip(model.parameters(), old_parameters)]\n",
        "        loss_w = torch.sum(torch.stack(loss_w))\n",
        "\n",
        "        loss += lam_reg*loss_w\n",
        "        \n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "\n",
        "def train_loss(model, dataloader, old_parameters, loss_fn, lam_reg):\n",
        "    loss = 0\n",
        "    loss_w = 0\n",
        "    idx = 0\n",
        "    for ipt, label in dataloader:\n",
        "        loss += loss_fn(model(ipt), label).item()\n",
        "        idx += 1\n",
        "    loss_fn_2 = nn.MSELoss(reduction='sum')\n",
        "    loss_w = [loss_fn_2(w, w_meta) for w, w_meta in zip(model.parameters(), old_parameters)]\n",
        "    loss_w = torch.sum(torch.stack(loss_w))\n",
        "    loss_w = lam_reg*(loss_w.item())\n",
        "    return (loss/idx + loss_w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDItUWVMGd6y"
      },
      "source": [
        "DP-SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDWTdb41GcEf"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import grad\n",
        "from torch.nn import parameter\n",
        "class MetaDPSGD():\n",
        "\n",
        "    def __init__(self, models, q):\n",
        "        self.models = models\n",
        "        self.keys = list(models[0].state_dict().keys())\n",
        "        self.q = q\n",
        "\n",
        "    def train_step(self, N_train_task,  inner_iters,\n",
        "                   meta_step_size, meta_batch_size,\n",
        "                lam_reg, optimizer_list, loss, maximum_norm, noise_multiplier, flag):\n",
        "\n",
        "        \"\"\"\n",
        "        Perform one training step of meta DP-SGD\n",
        "        :param base_learner: the model of base_learner\n",
        "        :param datasets: the data set\n",
        "        :param inner_iters: number of inner-loop iterations\n",
        "        :param meta_step_size: step size for meta algorithm\n",
        "        :param meta_batch_size: number of tasks sampled in each iteration\n",
        "        :param sigma: std of added noise to preserve privacy\n",
        "        :param lam_reg: regularization parameter\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        new_vars = [[] for _ in range(self.q)]\n",
        "        \n",
        "        task_index = task_sampling(N_train_task, meta_batch_size)\n",
        "\n",
        "        \n",
        "        old_state_dict_list = [copy.deepcopy(self.models[i].state_dict()) for i in range(self.q)]\n",
        "        old_parameters_list = [[copy.deepcopy(para) for para in self.models[i].parameters()] for i in range(self.q)]\n",
        "        for task in task_index:\n",
        "            best_model_index = -1\n",
        "            best_parameters = []\n",
        "            best_training_loss = np.inf\n",
        "            train_data = torch.load(train_path+str(task)+'.pt', map_location='cuda:0')\n",
        "            train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
        "            for i in range(self.q):\n",
        "                model = self.models[i]\n",
        "                optim = optimizer_list[i]\n",
        "                model_train(model, train_dataloader, old_parameters_list[i], inner_iters, optim, loss, lam_reg)\n",
        "                training_loss = train_loss(model, train_dataloader, old_parameters_list[i], loss, lam_reg)\n",
        "                if training_loss < best_training_loss:\n",
        "                    best_model_index = i\n",
        "                    best_training_loss = training_loss\n",
        "                    best_parameters = [copy.deepcopy(para) for para in model.parameters()]\n",
        "                model.load_state_dict(old_state_dict_list[i])\n",
        "\n",
        "            gradient = [-lam_reg*(v - val) for v, val in zip(best_parameters, old_parameters_list[best_model_index])]\n",
        "            #print(gradient)\n",
        "            if flag == True:\n",
        "                gradient = gradient_clipping(gradient, maximum_norm)\n",
        "            new_vars[best_model_index].append(gradient)\n",
        "            \n",
        "        \n",
        "        for i in range(self.q):\n",
        "            if new_vars[i]:\n",
        "                #gradient = average_vars(new_vars[i])\n",
        "                gradient= average_vars_batch(new_vars[i], meta_batch_size)\n",
        "                #print(gradient)\n",
        "\n",
        "                #gradient = Add_noise(gradient, noise_multiplier, maximum_norm, meta_batch_size)\n",
        "                new_states = meta_update(old_parameters_list[i], gradient, meta_step_size)\n",
        "            else:\n",
        "                new_states = copy.deepcopy(old_parameters_list[i])\n",
        "\n",
        "            if flag == True:\n",
        "                new_states = Add_noise(new_states, noise_multiplier, maximum_norm, meta_batch_size, meta_step_size)\n",
        "            state_dict = {}\n",
        "\n",
        "            for key, val in zip(self.keys, new_states):\n",
        "                state_dict[key] = val\n",
        "            self.models[i].load_state_dict(state_dict)\n",
        "                \n",
        "        #print(self.model.state_dict())\n",
        "\n",
        "    def evaluate(self,  inner_iters, optimizer_list, loss, lam_reg):\n",
        "        transfer_risk = []\n",
        "        old_state_dict_list = [copy.deepcopy(self.models[i].state_dict()) for i in range(self.q)]\n",
        "        old_parameters_list = [[copy.deepcopy(para) for para in self.models[i].parameters()] for i in range(self.q)]\n",
        "        for j in range(400):\n",
        "            idx = j+1\n",
        "            test_data = torch.load(test_path+str(idx)+'.pt', map_location='cuda:0')\n",
        "            train_set, test_set = torch.utils.data.random_split(test_data, [10, 40])\n",
        "            train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "\n",
        "            best_model_index = -1\n",
        "            best_training_loss = np.inf\n",
        "            best_parameters = []\n",
        "\n",
        "            for i in range(self.q):\n",
        "                model = self.models[i]\n",
        "                optim = optimizer_list[i]\n",
        "                model_train(model, train_loader, old_parameters_list[i], inner_iters, optim, loss, lam_reg)\n",
        "                training_loss = train_loss(model, train_loader, old_parameters_list[i], loss, lam_reg)\n",
        "                if training_loss < best_training_loss:\n",
        "                    best_model_index = i\n",
        "                    best_training_loss = training_loss\n",
        "            \n",
        "\n",
        "            model = self.models[best_model_index]\n",
        "            running_loss = 0\n",
        "            test_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n",
        "            for ipt, label in test_loader:\n",
        "                running_loss += loss(model(ipt), label).item()\n",
        "            transfer_risk.append(running_loss/40)\n",
        "            for i in range(self.q):\n",
        "                self.models[i].load_state_dict(old_state_dict_list[i])\n",
        "\n",
        "        print(np.average(transfer_risk))\n",
        "        return np.average(transfer_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6EB1nnzGrcm"
      },
      "source": [
        "Running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsODYQCDGsl2",
        "outputId": "ef5dd334-6177-46e7-d466-812be6b87779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epsilon: 3\n",
            "N_train_task 100\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 1.7982448384227756 iterated over 100 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.5587754706359145\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 1.7982448384227756 iterated over 100 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.3271878277438383\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 1.7982448384227756 iterated over 100 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "3.012020631756666\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 1.7982448384227756 iterated over 100 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.724055683488677\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 1.7982448384227756 iterated over 100 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.573492243957531\n",
            "epsilon: 3\n",
            "N_train_task 200\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 1.3755950383777618 iterated over 200 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.498220660986579\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 1.3755950383777618 iterated over 200 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.3195818922707288\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 1.3755950383777618 iterated over 200 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.267822003501984\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 1.3755950383777618 iterated over 200 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.228765767283187\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 1.3755950383777618 iterated over 200 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.43463675161547\n",
            "epsilon: 3\n",
            "N_train_task 300\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 1.197485072195053 iterated over 300 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.3697305830419095\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 1.197485072195053 iterated over 300 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.270367778276974\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 1.197485072195053 iterated over 300 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.2522426098024426\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 1.197485072195053 iterated over 300 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.40854089901832\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 1.197485072195053 iterated over 300 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.24757098078669\n",
            "epsilon: 3\n",
            "N_train_task 400\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 1.0918758223018648 iterated over 400 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.0820703449918296\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 1.0918758223018648 iterated over 400 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.2489860544836096\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 1.0918758223018648 iterated over 400 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.437721861005496\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 1.0918758223018648 iterated over 400 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.393904797726321\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 1.0918758223018648 iterated over 400 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.2817718929851583\n",
            "epsilon: 3\n",
            "N_train_task 500\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 1.0225956360607151 iterated over 500 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.1501532263871392\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 1.0225956360607151 iterated over 500 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.1992336984341305\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 1.0225956360607151 iterated over 500 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.39615240011031\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 1.0225956360607151 iterated over 500 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.134595607544781\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 1.0225956360607151 iterated over 500 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.443221907118938\n",
            "epsilon: 3\n",
            "N_train_task 600\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.9735134666156768 iterated over 600 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "2.1711693698549466\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.9735134666156768 iterated over 600 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "2.2797853309467127\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.9735134666156768 iterated over 600 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "2.1729961149909376\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.9735134666156768 iterated over 600 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "2.1255761800065502\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.9735134666156768 iterated over 600 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "2.0160015207281763\n",
            "epsilon: 3\n",
            "N_train_task 700\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.936976587633133 iterated over 700 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "2.2106156859619572\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.936976587633133 iterated over 700 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "2.036661769134656\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.936976587633133 iterated over 700 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "2.2062146236743283\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.936976587633133 iterated over 700 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "2.2691156443075244\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.936976587633133 iterated over 700 steps satisfies differential privacy with eps = 3 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "2.283333978024301\n",
            "{3: [2.6391063715165255, 2.34980541513159, 2.3096905701852672, 2.288890990238483, 2.2646713679190595, 2.1531057033054646, 2.201188340220553]}\n",
            "epsilon: 10\n",
            "N_train_task 100\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 0.8931404180202486 iterated over 100 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.3289398607883647\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 0.8931404180202486 iterated over 100 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.395588199437274\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 0.8931404180202486 iterated over 100 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.3748372966757048\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 0.8931404180202486 iterated over 100 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.2566975647122245\n",
            "DP-SGD with sampling rate = 10% and noise_multiplier = 0.8931404180202486 iterated over 100 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "evaluation start:..............\n",
            "2.4358092537108273\n",
            "epsilon: 10\n",
            "N_train_task 200\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 0.7611820121593476 iterated over 200 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.196519181083923\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 0.7611820121593476 iterated over 200 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.159077906642884\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 0.7611820121593476 iterated over 200 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.1691315262295636\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 0.7611820121593476 iterated over 200 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.229508557723911\n",
            "DP-SGD with sampling rate = 5% and noise_multiplier = 0.7611820121593476 iterated over 200 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.145922227836631\n",
            "epsilon: 10\n",
            "N_train_task 300\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 0.6995079655017853 iterated over 300 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.293946150059019\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 0.6995079655017853 iterated over 300 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.1402664578663235\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 0.6995079655017853 iterated over 300 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "1.9790878410186252\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 0.6995079655017853 iterated over 300 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.2012770417620016\n",
            "DP-SGD with sampling rate = 3.33% and noise_multiplier = 0.6995079655017853 iterated over 300 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.134436341858456\n",
            "epsilon: 10\n",
            "N_train_task 400\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 0.6626938680706025 iterated over 400 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.1532706300597995\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 0.6626938680706025 iterated over 400 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.069996258434626\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 0.6626938680706025 iterated over 400 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.1761691787267243\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 0.6626938680706025 iterated over 400 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.4984712916826566\n",
            "DP-SGD with sampling rate = 2.5% and noise_multiplier = 0.6626938680706025 iterated over 400 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "1.990366935935503\n",
            "epsilon: 10\n",
            "N_train_task 500\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 0.6374090518245699 iterated over 500 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "1.9862288762689724\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 0.6374090518245699 iterated over 500 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.128888218248114\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 0.6374090518245699 iterated over 500 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.0211810435599267\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 0.6374090518245699 iterated over 500 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.0965120762526994\n",
            "DP-SGD with sampling rate = 2% and noise_multiplier = 0.6374090518245699 iterated over 500 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "2.085833880507345\n",
            "epsilon: 10\n",
            "N_train_task 600\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.6185832521533966 iterated over 600 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "1.8837078746256497\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.6185832521533966 iterated over 600 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "1.9984727553962933\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.6185832521533966 iterated over 600 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "2.119628875371688\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.6185832521533966 iterated over 600 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "1.9457563863206633\n",
            "DP-SGD with sampling rate = 1.67% and noise_multiplier = 0.6185832521533966 iterated over 600 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "2.0581643620319072\n",
            "epsilon: 10\n",
            "N_train_task 700\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.6038112464351654 iterated over 700 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "2.0641246945582576\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.6038112464351654 iterated over 700 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "1.9127516304158962\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.6038112464351654 iterated over 700 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "1.9604782943082661\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.6038112464351654 iterated over 700 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "2.09609277192904\n",
            "DP-SGD with sampling rate = 1.43% and noise_multiplier = 0.6038112464351654 iterated over 700 steps satisfies differential privacy with eps = 10 and delta = 1e-05.\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "2.0772745423345556\n",
            "{3: [2.6391063715165255, 2.34980541513159, 2.3096905701852672, 2.288890990238483, 2.2646713679190595, 2.1531057033054646, 2.201188340220553], 10: [2.3583744350648788, 2.1800318799033827, 2.1498027665128854, 2.1776548589678617, 2.0637288189674114, 2.0011460507492402, 2.0221443867092033]}\n",
            "epsilon: 10000\n",
            "N_train_task 100\n",
            "100\n",
            "evaluation start:..............\n",
            "2.3233938257986937\n",
            "100\n",
            "evaluation start:..............\n",
            "2.217039463469533\n",
            "100\n",
            "evaluation start:..............\n",
            "2.351651913601184\n",
            "100\n",
            "evaluation start:..............\n",
            "2.2113025375440163\n",
            "100\n",
            "evaluation start:..............\n",
            "2.2645049889603506\n",
            "epsilon: 10000\n",
            "N_train_task 200\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.2086542439564947\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.114695598570597\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.163546818150395\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.1477834388862265\n",
            "100\n",
            "200\n",
            "evaluation start:..............\n",
            "2.0811201443630063\n",
            "epsilon: 10000\n",
            "N_train_task 300\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.0117021580911616\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.0245641558651926\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.0941170886255334\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.083948919799887\n",
            "100\n",
            "200\n",
            "300\n",
            "evaluation start:..............\n",
            "2.0383562692672776\n",
            "epsilon: 10000\n",
            "N_train_task 400\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "1.896014988019965\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "1.947152106095538\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "1.975019686773285\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "1.856290061924368\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "evaluation start:..............\n",
            "2.0355152097165465\n",
            "epsilon: 10000\n",
            "N_train_task 500\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "1.9669065525566418\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "1.8501432233737671\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "1.9741076307994208\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "1.9049646538419471\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "evaluation start:..............\n",
            "1.9549246105531322\n",
            "epsilon: 10000\n",
            "N_train_task 600\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "2.0009035275033757\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "1.869494299709487\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "1.8868295182469734\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "1.8766065721094356\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "evaluation start:..............\n",
            "1.9065324107009338\n",
            "epsilon: 10000\n",
            "N_train_task 700\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "1.9806106989463959\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "1.7719422059110932\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "1.8808718325283267\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "1.8620829690817085\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "evaluation start:..............\n",
            "1.8283437724257687\n",
            "{3: [2.6391063715165255, 2.34980541513159, 2.3096905701852672, 2.288890990238483, 2.2646713679190595, 2.1531057033054646, 2.201188340220553], 10: [2.3583744350648788, 2.1800318799033827, 2.1498027665128854, 2.1776548589678617, 2.0637288189674114, 2.0011460507492402, 2.0221443867092033], 10000: [2.2735785458747557, 2.1431600487853437, 2.05053771832981, 1.9419984105059407, 1.930209334224982, 1.908073265654041, 1.8647702957786585]}\n",
            "{3: [2.6391063715165255, 2.34980541513159, 2.3096905701852672, 2.288890990238483, 2.2646713679190595, 2.1531057033054646, 2.201188340220553], 10: [2.3583744350648788, 2.1800318799033827, 2.1498027665128854, 2.1776548589678617, 2.0637288189674114, 2.0011460507492402, 2.0221443867092033], 10000: [2.2735785458747557, 2.1431600487853437, 2.05053771832981, 1.9419984105059407, 1.930209334224982, 1.908073265654041, 1.8647702957786585]}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = torch.device('cuda:0')\n",
        "meta_learners = []\n",
        "optimizers = []\n",
        "q = 2\n",
        "\n",
        "for i in range(q):\n",
        "    model = Model().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.07)\n",
        "    meta_learners.append(model)\n",
        "    optimizers.append(optimizer)\n",
        "\n",
        "lam_reg = 0.4\n",
        "inner_iteration = 20\n",
        "meta_step_size = 0.7\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "#-----------------hyperparamters-------------\n",
        "N_train_task = 50\n",
        "sampling_rate = 0.05\n",
        "epoch = 3\n",
        "maximum_norm = 1\n",
        "noise_multiplier = 1\n",
        "#--------------------------------------------------\n",
        "result = {}\n",
        "for epsilon in [3,10,10000]:\n",
        "    result[epsilon] = []\n",
        "    for N_train_task in range(100, 701, 100):\n",
        "        print(\"epsilon:\" ,epsilon)\n",
        "        print(\"N_train_task\", N_train_task)\n",
        "        running_loss = 0\n",
        "        for i in range(5): \n",
        "            data_generation()\n",
        "            for j in range(q):\n",
        "                meta_learner = meta_learners[j]    \n",
        "                for layer in meta_learner.children():\n",
        "                    if hasattr(layer, 'reset_parameters'):\n",
        "                        layer.reset_parameters()\n",
        "            meta_iteration = int(N_train_task)\n",
        "            meta_batch_size = 10\n",
        "            if epsilon > 100:\n",
        "                noise_multiplier = 0\n",
        "                maximum_norm = 1\n",
        "                flag = False\n",
        "            else:\n",
        "                noise_multiplier = compute_noise(N_train_task, meta_batch_size, epsilon, meta_batch_size, 1e-5, 1e-6)\n",
        "                maximum_norm = 1\n",
        "                flag = True\n",
        "            meta_SGD = MetaDPSGD(meta_learners, q)\n",
        "            idx =1\n",
        "            for _ in range(meta_iteration):\n",
        "                idx += 1\n",
        "                if idx%100 == 0:\n",
        "                    print(idx)\n",
        "                meta_SGD.train_step(N_train_task, inner_iteration, meta_step_size, meta_batch_size, lam_reg, optimizers, loss_fn, maximum_norm, noise_multiplier, flag)            \n",
        "                # if idx%200 == 0:\n",
        "                #      print(\"evaluation start:..............\")\n",
        "                #      meta_SGD.evaluate(inner_iteration, optimizers, loss_fn, lam_reg)\n",
        "            print(\"evaluation start:..............\")\n",
        "            running_loss += meta_SGD.evaluate(inner_iteration, optimizers, loss_fn, lam_reg)\n",
        "        \n",
        "        result[epsilon].append(running_loss/5)\n",
        "    print(result)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N9mXs5lxRc5"
      },
      "outputs": [],
      "source": [
        "for model in meta_learners:\n",
        "    print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_79FMwtatnL0"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0')\n",
        "meta_learner = Model().to(device)\n",
        "lam_reg = 0.5\n",
        "inner_iteration = 20\n",
        "\n",
        "optimizer = optim.SGD(meta_learner.parameters(), lr=0.07)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "meta_SGD = MetaDPSGD(meta_learner)\n",
        "meta_SGD.evaluate(inner_iteration, optimizer, loss_fn, lam_reg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DP_meta_single_multi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}